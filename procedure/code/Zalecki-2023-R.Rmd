---
title: "Who is the public in public libraries? Exploring the spatial variations of the changing dynamics of library services in Chicago, IL"
author: "Alexandra Ola Zalecki"
date: "`r Sys.Date()`"
output: html_document
editor_options:
  markdown:
    wrap: sentence
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding, output_dir = "../../docs/report") })
---

# Abstract

Considering the privatization of space within urban landscapes and growing disparities in equity, libraries have incredible potential to shed light on community needs and the power of public space. This paper investigates the ways in which library services and uses vary across space and the ways in which they map onto the diverse socioeconomic & demographic characteristics of the neighborhoods that they serve. To answer this question, I map socio-demographic variables from the 2021 American Community Survey onto library service areas generated using Thiessen polygons and population weighted reaggregation. I surveyed the Chicago Public Library profiles to collect library service data which was then analyzed alongside the socio-demographic variables. The study revealed that library service areas display significant socio-economic and demographic variability that reflect Chicagoâ€™s racial and economic segregation. Additionally, socio-economic and demographic characteristics shape the services and programming available at local libraries. Affluent and predominantly white areas showed higher rates of circulation and availability of mental health services while neighborhoods that were predominantly poor, Black and/or Latinx Socio-economic and demographic characteristics significantly shape the services, programming, and amenities at Chicago libraries, with affluent and predominantly white areas receiving higher circulation and specialized services, while disadvantaged, predominantly Black and Latinx areas rely more on non-traditional services like internet access and social support. 

## Study Metadata

- `Key words`: public space, libraries, population weighted aggregation, service areas 
- `Subject`: Social and Behavioral Sciences: Geography: Human Geography
- `Date created`: 11/28/2023
- `Date modified`: 1/16/2024
- `Spatial Coverage`: Chicago, IL
- `Spatial Resolution`: Census Tracts, Census Blocks, Library Service Areas
- `Spatial Reference System`: EPSG:32616 
- `Temporal Coverage`: 2017-2023
- `Temporal Resolution`: Specify the temporal resolution of your study---i.e. the duration of time for which each observation represents or the revisit period for repeated observations

# Study design

This is **an original study** as part of my senior thesis work.The goal of this research is to not only map the geographic distribution of libraries in Chicago, IL but to investigate the ways in which library services vary across space and if they relate to the socioeconomic & demographic characteristics of the neighborhoods that they serve. This study specifically aims to answer the following questions: (1) How do library service catchment areas differ along socio-economic and demographic lines in Chicago? (2) To what extent do the socio-economic and demographic characteristics shape the services, programming and amenities available at these libraries? 

# Materials and procedure

## Computational environment

```{r environment-setup, warning = FALSE}
# record all the packages you are using here
# this includes any calls to library(), require(),
# and double colons such as here::i_am()
packages <- c( 
  "tidycensus", "tidyverse", "sf", "classInt", "readr", "tigris","rstudioapi", "here", "s2", "pastecs", "tmap", "knitr", 
  "kableExtra", "broom", "usethis", "deldir", "spatstat", "webshot", "rstatix", "RColorBrewer"
)

# force all conflicts to become errors
# if you load dplyr and use filter(), R has to guess whether you mean dplyr::filter() or stats::filter()
# the conflicted package forces you to be explicit about this
# disable at your own peril
# https://conflicted.r-lib.org/
require(conflicted)

# load and install required packages
# https://groundhogr.com/
if (!require(groundhog)) {
  install.packages("groundhog")
  require(groundhog)
}

if(!require(here)){
  install.packages("here")
  require(here)
}

# this date will be used to determine the versions of R and your packages
# it is best practice to keep R and its packages up to date
groundhog.day <- "2025-01-14"
set.groundhog.folder("../../data/scratch/groundhog/")

# this replaces any library() or require() calls
groundhog.library(packages, groundhog.day)
# you may need to install a correct version of R
# you may need to respond OK in the console to permit groundhog to install packages
# you may need to restart R and rerun this code to load installed packages
# In RStudio, restart r with Session -> Restart Session

# record the R processing environment
# alternatively, use devtools::session_info() for better results
writeLines(
  capture.output(sessionInfo()),
  here("procedure", "environment", paste0("r-environment-", Sys.Date(), ".txt"))
)

# save package citations
knitr::write_bib(c(packages, "base"), file = here("software.bib"))

# set up default knitr parameters
# https://yihui.org/knitr/options/
knitr::opts_chunk$set(
  echo = FALSE, # Run code, show outputs (don't show code)
  fig.retina = 4,
  fig.width = 8,
  fig.path = paste0(here("results", "figures"), "/")
)

#Switch the graphics output from raster to vector
knitr::opts_chunk$set(dev="png")

```
## Data and variables

Each of the next subsections describes one data source.

Primary data sources are to include the following.

### Library Services and Programs 

Data on non-traditional library programming and features were collected over a period of two days from the 81 library profiles found on the Chicago Public Library website. The presence or absence of special programming or a certain feature like 'YouMedia', 'Teacher in the Library', etc. were manually coded as a Boolean into an excel spreadsheet. 

```{r load-website-data}
# Load website survey data from the Github data folder 

web = read_csv("https://raw.githubusercontent.com/azalecki/Zalecki-2023/main/data/raw/public/WS_1_29_24.csv")
```


```{r table}

# Create a simple data frame
feature_table <- data.frame(
  Feature = c("Citizenship Corner", "Cyber Navigators", "YouMedia", "Teacher in the Library", 
              "Mental Health and Social Services", "Wi-Fi Hotspot Lending", 
              "Chromebook Kit Lending", "Non-English Language Materials"),
  Definition = c(
    "Enhanced collections on immigration and U.S citizenship, free assistance, and dissemination of US Citizenship and Immigration Services (USCIS) publications in the languages most commonly spoken in Chicago",
    "One-on-one sessions with technology tutors that build computer literacy and digital skills",
    "Teenager digital learning and makerspace",
    "Free drop-in homework help program for school-age students with accredited teachers",
    "Staffed with mental health clinicians or hosts a mental health focused organization",
    "A program that lends portable wifi hotspots that you can use to connect a mobile-enabled device to the internet",
    "A resident of Chicago with an active adult CPL card may borrow a Google Chrome laptop for three weeks",
    "The library provides a multilingual materials collection and circulates materials in a language other than English"
  )
)

# If you're using the knitr package to generate the table:
kable(feature_table)


```
 

Secondary data sources for the study are to include the following. 

### Chicago Shapefile 

I extracted the Chicago boundary as a geographical unit from the US Census Bureau using the tigris package. 


```{r download-places, eval= FALSE}
# Run this chunk the first time you run the code. Once the data is saved all you have to do is refer to the {r load-clip-places} chunk and run that code to reintroduce the data into the environment. 

# Download all places defined by the US Census
il_places <- places(state = "IL")

# Save data to repository 
saveRDS(il_places, here("data", "raw", "public", "il_places.RDS"))

```

```{r load-clip-places}
# Load Census places for Illinois
il_places <- readRDS(here("data", "raw", "public", "il_places.RDS"))

```
 
 
### Download block data from the 2020 Census for Cook County, IL  

Population data for this study is referenced at the block level for the whole of Cook County, IL. The year that the data is derived from is 2020.

```{r blocks-table}
# Run this chunk the first time you run the code. Once the data is saved all you have to do is refer to the {r load-blocks} chunk and run that code to reintroduce the data into the environment. 

# Download all blocks located in Cook County, IL defined by the US Census. This dataframe will not have any spatial geometry and will just exist in table form as a reference. 

cook_blocks_tbl <-get_decennial(geography="block", state="IL", county="Cook", year=2020,
                         variables=c(block_pop="P1_001N", block_hu="H1_001N")) %>% 
  pivot_wider(id_cols = "GEOID", names_from = variable, values_from = value)

# Save data to repository 
saveRDS(cook_blocks_tbl, here("data", "raw", "public", "cook_blocks_tbl.RDS"))

```
  
```{r blocks-shape, eval= FALSE}
# Run this chunk the first time you run the code. Once the data is saved all you have to do is refer to the {r load-blocks} chunk and run that code to reintroduce the data into the environment. 

# Download all blocks located in Cook County, IL defined by the US Census. This dataframe **will** have any spatial geometry. We will be manipulating this data. 

cook_blocks_shp <- get_decennial(
  geography = "block",
  table = "P1",
  county = "Cook",
  state = "IL",
  year = 2020,
  output = "wide",
  cache_table = TRUE,
  geometry = TRUE,
  keep_geo_vars = TRUE)%>%
  st_set_crs(st_crs("+proj=utm +zone=16 +datum=WGS84"))

# Save data to repository 

saveRDS(cook_blocks_shp, here("data", "raw", "public", "cook_blocks_shp.RDS"))

```

```{r load-blocks}

#Load block datainto the environment 

cook_blocks_tbl <- readRDS(here("data", "raw", "public", "cook_blocks_tbl.RDS"))
cook_blocks_shp <- readRDS(here("data", "raw", "public", "cook_blocks_shp.RDS"))
                  
```

### Download tract data from the 2021 American Community Survey(ACS) 

```{r download-tract-table}
# Run this chunk the first time you run the code. Once the data is saved all you have to do is refer to the {r load-blocks} chunk and run that code to reintroduce the data into the environment. 

# Download all tracts located in Cook County, IL defined by the US Census. This dataframe will not have any spatial geometry and will just exist in table form as a reference. 

cook_tracts_tbl <-get_decennial(geography="tract", state="IL", county="Cook", year=2020,
                         variables=c(tract_pop="P1_001N", tract_hu="H1_001N")) %>% 
  pivot_wider(id_cols = "GEOID", names_from = variable, values_from = value) %>% 
  arrange(GEOID)

# Save data to the repository 

saveRDS(cook_tracts_tbl, here("data", "raw", "public", "cook_tracts_tbl.RDS"))
```

```{r download-tracts-shp, eval= FALSE}
# Run this chunk the first time you run the code. Once the data is saved all you have to do is refer to the {r load-blocks} chunk and run that code to reintroduce the data into the environment. 

# Download all tracts located in Cook County, IL defined by the US Census. This dataframe **will** have spatial geometry and will be manipulated later.  

cook_tracts_shp <- tracts(
                state = "IL",
                county = "Cook",
                cb = FALSE,
                resolution = "500k",
                year = 2020)%>%
  st_set_crs(st_crs("+proj=utm +zone=16 +datum=WGS84"))

# Save data to the repository

saveRDS(cook_tracts_shp, here("data", "raw", "public", "cook_tracts_shp.RDS"))

```

```{r load-tracts}

# Load tract data into the environment 

cook_tracts_tbl <- readRDS(here("data", "raw", "public", "cook_tracts_tbl.RDS"))
cook_tracts_shp <- readRDS(here("data", "raw", "public", "cook_tracts_shp.RDS"))
                  
```
### Download social-demographic data from the 2021 American Community Survey(ACS) 

Sociodemographic variables included in this study: 

Median family income,
Employment status,
Poverty Status,
Total population, 
Race, 
Ethnicity,
Age, 
Sex, 
Nativity,
Educational attainment.

```{r api-key, install = TRUE, eval = FALSE}
# Load in Census API Key. Get your own API key here: https://www.census.gov/data/developers.html 

census_api_key("058bab25964a0d33dc97ba789df8df55ba443855")
```

```{r query-acs-data, eval = FALSE}

# Query Social & Demographic data tables with Census tract boundaries
# All of the following code is pulling ACS data for the year 2021 at the census tract level for Cook County, IL. 

# Run this chunk the first time you run the code. Once the data is saved all you have to do is refer to the {r load-query-acs-data} chunk and run that code to reintroduce the data into the environment. 


 # Age and Sex Table 

  as_acs <- get_acs(geography = "tract",table = "B01001",
    county = "Cook",
    state = "IL",
    year = 2021,
    output = "wide",
    cache_table = TRUE,
    geometry = TRUE,
    keep_geo_vars = TRUE)%>%
    st_drop_geometry()

 # Race & Ethnicity Table
 
  race_acs <- get_acs(
    geography = "tract",
    table = "B03002",
    county = "Cook",
    state = "IL",
    year = 2021,
    output = "wide",
    cache_table = TRUE,
    geometry = TRUE,
    keep_geo_vars = TRUE)%>%
    st_drop_geometry()
  
  # Household Type 
  
  hhold_acs <- get_acs(
    geography = "tract",
    table = "B11003",
    county = "Cook",
    state = "IL",
    year = 2021,
    output = "wide",
    cache_table = TRUE,
    geometry = TRUE,
    keep_geo_vars = TRUE)%>%
    st_drop_geometry()
  
  # Educational Attainment Table 

  edu_acs <- get_acs(
    geography = "tract",
    table = "B15003",
    county = "Cook",
    state = "IL",
    year = 2021,
    output = "wide",
    cache_table = TRUE,
    geometry = TRUE,
    keep_geo_vars = TRUE)%>%
    st_drop_geometry()
  
  # Disability Status Table 
  
  dis_acs <- get_acs(
    geography = "tract",
    table = "B18101",
    county = "Cook",
    state = "IL",
    year = 2021,
    output = "wide",
    cache_table = TRUE,
    geometry = TRUE,
    keep_geo_vars = TRUE)%>%
    st_drop_geometry()

  # School Enrollment 
 
  enr_acs <- get_acs(
    geography = "tract",
    table = "B14001",
    county = "Cook",
    state = "IL",
    year = 2021,
    output = "wide",
    cache_table = TRUE,
    geometry = TRUE,
    keep_geo_vars = TRUE)%>%
    st_drop_geometry()
 
# Employment Table 

  emp_acs <- get_acs(
    geography = "tract",
    table = "B23025",
    county = "Cook",
    state = "IL",
    year = 2021,
    output = "wide",
    cache_table = TRUE,
    geometry = TRUE,
    keep_geo_vars = TRUE)%>%
    st_drop_geometry()
 
# Nativity Table 
 
  nat_acs <- get_acs(
    geography = "tract",
    table = "B05012",
    county = "Cook",
    state = "IL",
    year = 2021,
    output = "wide",
    cache_table = TRUE,
    geometry = TRUE,
    keep_geo_vars = TRUE)%>%
    st_drop_geometry()
 
# Language Spoken at Home

   lang_acs <- get_acs(
     geography = "tract",
     table = "B06007",
     county = "Cook",
     state = "IL",
     year = 2021,
     output = "wide",
     cache_table = TRUE,
     geometry = TRUE,
     keep_geo_vars = TRUE)%>%
     st_drop_geometry()
 
# Computers at Home
 
  comp_acs <- get_acs(
    geography = "tract",
    table = "B28010",
    county = "Cook",
    state = "IL",
    year = 2021,
    output = "wide",
    cache_table = TRUE,
    geometry = TRUE,
    keep_geo_vars = TRUE)%>%
     st_drop_geometry()
 
 # Household Income Table 
inc_acs <- get_acs(
   geography = "tract",
   table = "B19001",
   county = "Cook",
   state = "IL",
   year = 2021,
   output = "wide",
   cache_table = TRUE,
   geometry = TRUE,
   keep_geo_vars = TRUE)%>%
    st_drop_geometry()

# Poverty Status 
pov_acs <- get_acs(
   geography = "tract",
   table = "B17001",
   county = "Cook",
   state = "IL",
   year = 2021,
   output = "wide",
   cache_table = TRUE,
   geometry = TRUE,
   keep_geo_vars = TRUE)%>%
    st_drop_geometry()

#Median Family Income
m_inc_acs <- get_acs(
   geography = "tract",
   table = "B19013",
   county = "Cook",
   state = "IL",
   year = 2021,
   output = "wide",
   cache_table = TRUE,
   geometry = TRUE,
   keep_geo_vars = TRUE) %>%
  st_set_crs(st_crs("+proj=utm +zone=16 +datum=WGS84"))

# Save query results to the repository 

saveRDS(edu_acs, here("data", "raw", "public", "edu_acs.RDS"))
saveRDS(as_acs, here("data", "raw", "public", "as_acs.RDS"))
saveRDS(race_acs, here("data", "raw", "public", "race_acs.RDS"))
saveRDS(hhold_acs, here("data", "raw", "public", "hhold_acs.RDS"))
saveRDS(dis_acs, here("data", "raw", "public", "dis_acs.RDS"))
saveRDS(enr_acs, here("data", "raw", "public", "enr_acs.RDS"))
saveRDS(emp_acs, here("data", "raw", "public", "emp_acs.RDS"))
saveRDS(nat_acs, here("data", "raw", "public", "nat_acs.RDS"))
saveRDS(lang_acs, here("data", "raw", "public", "lang_acs.RDS"))
saveRDS(comp_acs, here("data", "raw", "public", "comp_acs.RDS"))
saveRDS(inc_acs, here("data", "raw", "public", "inc_acs.RDS"))
saveRDS(pov_acs, here("data", "raw", "public", "pov_acs.RDS"))
saveRDS(m_inc_acs, here("data", "raw", "public", "m_inc_acs.RDS"))


```

```{r load-query-acs-data}

#Load ACS Data into the environment

edu_acs <- readRDS(here("data", "raw", "public", "edu_acs.RDS"))
as_acs <- readRDS(here("data", "raw", "public", "as_acs.RDS"))
race_acs <- readRDS(here("data", "raw", "public", "race_acs.RDS"))
hhold_acs <- readRDS(here("data", "raw", "public", "hhold_acs.RDS"))
dis_acs <- readRDS(here("data", "raw", "public", "dis_acs.RDS"))
enr_acs <- readRDS(here("data", "raw", "public", "enr_acs.RDS"))
emp_acs <- readRDS(here("data", "raw", "public", "emp_acs.RDS"))
nat_acs <- readRDS(here("data", "raw", "public", "nat_acs.RDS"))
lang_acs <- readRDS(here("data", "raw", "public", "lang_acs.RDS"))
comp_acs <- readRDS(here("data", "raw", "public", "comp_acs.RDS"))
inc_acs <- readRDS(here("data", "raw", "public", "inc_acs.RDS"))
m_inc_acs <- readRDS(here("data", "raw", "public", "m_inc_acs.RDS"))
pov_acs <- readRDS(here("data", "raw", "public", "pov_acs.RDS"))

```

### Public Library Locations

The Chicago Data Portal maintains a data set of all Chicago Public Library Locations, contact information and usual hours of operation.Prior to uploading the CSV file into the Github site I used Microsoft Excel to manually separate the Longitude and Latitude values into two separate columns.The locations of the 81 libraries were plotted as points in GIS using their latitude and longitude coordinates from this data set. 

```{r cpl-data, warning = FALSE}

#Load Chicago Public Library addresses from CSV file found in Folder: data/raw/public/CPL-Locations.csv

cpl_data = read_csv("https://raw.githubusercontent.com/azalecki/Zalecki-2023/main/data/raw/public/CPL-Locations.csv") %>% tibble()

# Create points layer using Longitude and Latitude columns and set projection to UTM Zone 16, EPSG: 32616

points <- cpl_data %>%
  st_as_sf(coords = c("Longitude", "Latitude")) %>%
  st_set_crs(st_crs("+proj=utm +zone=16 +datum=WGS84"))

```

## Bias and threats to validity

**Edge/shape effects when creating polygons to represent library service/catchment areas**

Visualizing catchment areas for libraries is my first objective because, unlike primary schools that have definite attendance boundaries, libraries do not have proper "service areas." In the past, Thiessen/Voronoi polygons have been used to map catchment or service areas by proximity to points. As explained by Flitter et al(nd), GIS tools that generate Thiessen polygons draw shapes around a layer of point data where every location within one shape is nearer to its center point than all other points in the layer. These proximal regions assume that people are more likely to visit the library closest to them and as a result library services should reflect their local constituents. I recognize that this method has its flaws because this is not always the case. Some people may frequent libraries outside of their residential neighborhood for a variety of reasons and there is no way of accurately tracking that. The other option would be to draw buffers around library points like in the method we saw in the Kang et al. (year) study or calculate a network analysis. Thiessen polygons are, however, the simpler and computationally less intense option to a full-on network analysis. Although they might seem arbitrary I have attempted to improve the validity by including a population-weighted aggregation to more accurately estimate the neighborhood characteristics of the library service areas.

## Data transformations

After compiling all of table and geographic data necessary for this project, I selected for only the city of Chicago from all US Census defined places. This geographic unit will be used as a sort of "cookie cutter" in later parts of this workflow. 

```{r clip-places}

# Filter out the city of Chicago boundary from the Census Places data 

chi <- il_places %>%
  dplyr::filter(NAME == 'Chicago')%>%
  st_set_crs(st_crs("+proj=utm +zone=16 +datum=WGS84"))

# Plot geometry to verify 

plot(chi$geometry)
```

### Processing block data

In order to complete a population weighted reaggregation, I prepared the population data by filtering out the blocks with no population and clipping by the Chicago boundary. Then I selected for the columns that I wanted to keep working with to simplify the data table. The columns I selected for included: TRACTCE20, BLOCKCE20, GEOID, ALAND20, AWATER20, HOUSING20, POP20, geometry. 

```{r filter-blocks, warning = FALSE}

# This part of the workflow is just cleaning up and simplifying the census blocks raw data before moving forward

# Clip blocks data with spatial geometry by Chicago Boundary 

chi_blocks_shp <- st_intersection(cook_blocks_shp, chi)%>%
  st_collection_extract("POLYGON")%>%

# Simplify table by selecting for columns that I know I will need 
             select(GEOID,geometry)

# Make a reference table to come back to if needed 
chi_blocks_list<-chi_blocks_shp %>% 
  select(GEOID) %>% 
  as.tibble()

```
```{r filter-tracts}
# This part of the workflow is just cleaning up and simplifying the census tract raw data before moving forward

# Clip tract data with spatial geometry by Chicago Boundary
chi_tracts_shp <-  st_intersection(cook_tracts_shp, chi)%>%
  st_collection_extract("POLYGON")%>%

  # Simplify table by selecting for columns that I know I will need 
             select(GEOID,geometry)

# Make a reference table to come back to if needed 
chi_tracts_list<-chi_tracts_shp %>% 
  select(GEOID) %>% 
  as.tibble()

```


### Creating library catchment areas

To create proximal zones I generated Thiessen polygons from the library points. Thiessen polygons or a Voronoi diagram is a type tessellation; a tiling of a surface with geometric shapes with no overlaps or gaps. Every point within a polygon is nearer to its central point than any other point in the layer. Finally, I clipped the Voronoi diagram by the Chicago boundary. 

```{r voronoi-polygons, warning = FALSE}

# Generate Thiessen/Voronoi polygons from library points

vorpoly <- st_union(points)%>%
  st_voronoi()%>%
  st_collection_extract("POLYGON")%>%
  st_sf %>%
  st_cast


# Because I had to union the points prior to st_voronoi() function the library attributes were lost
# Rejoin attributes from library points data to voronoi polygons 

vorjoin <- st_join(vorpoly, points)

# Clip Thiessen polygons by Chicago boundary 
chi_vor <- st_intersection(vorjoin, chi)%>%
  st_set_crs(st_crs("+proj=utm +zone=16 +datum=WGS84"))
  

```

```{r map-thiessen}
# Plot polygons on a map with library points

vor_map <- tmap_mode("plot")
           tm_shape(chi_vor)+
              tm_borders(col="black" )+
           tm_shape(points) +
              tm_dots(size=0.05, col = "red")+ 
           tm_layout(legend.position = c("left", "bottom")) +
           tm_add_legend("symbol", col = "red", size = 0.5, labels = "Library Points")
           
vor_map
```

### ACS data transformations

The ACS classifies the data it collects in its own way but I wanted to reclassify it into different categories.

After creating the new classifications, I selected for the columns that I wanted to keep and work with. This included all of the necessary geographic identifiers(STATEFP, COUNTYFP, TRACTCE, GEOID, NAME.X, ALAND, AWATER, geometry) and the source fields I had created in the previous step. Finally, I clipped the table by the Chicago boundary so to only include tracts that are within the city of Chicago. 

```{r new-bins}

# Delineate age categories 

as_acs$child <- c(as_acs$B01001_003E + 
                  as_acs$B01001_004E + 
                  as_acs$B01001_005E + 
                  as_acs$B01001_027E + 
                  as_acs$B01001_028E + 
                  as_acs$B01001_029E)

as_acs$teen <- c(as_acs$B01001_006E + 
                 as_acs$B01001_007E +
                 as_acs$B01001_030E +
                 as_acs$B01001_031E)

as_acs$yad <- c(as_acs$B01001_008E + 
                as_acs$B01001_009E + 
                as_acs$B01001_010E +
                as_acs$B01001_011E + 
                as_acs$B01001_032E + 
                as_acs$B01001_033E + 
                as_acs$B01001_034E + 
                as_acs$B01001_035E)

as_acs$mad <- c(as_acs$B01001_012E + 
                as_acs$B01001_013E +
                as_acs$B01001_014E + 
                as_acs$B01001_015E +
                as_acs$B01001_016E +
                as_acs$B01001_036E +
                as_acs$B01001_037E +
                as_acs$B01001_038E +
                as_acs$B01001_039E +
                as_acs$B01001_040E)

as_acs$sen <- c(as_acs$B01001_017E + 
                as_acs$B01001_018E + 
                as_acs$B01001_019E +
                as_acs$B01001_020E +
                as_acs$B01001_021E +
                as_acs$B01001_022E +
                as_acs$B01001_023E + 
                as_acs$B01001_024E +
                as_acs$B01001_025E +
                as_acs$B01001_041E +
                as_acs$B01001_042E +
                as_acs$B01001_043E +
                as_acs$B01001_044E +
                as_acs$B01001_045E +
                as_acs$B01001_046E +
                as_acs$B01001_047E +
                as_acs$B01001_048E +
                as_acs$B01001_049E)

as_acs$male <- c(as_acs$B01001_002E)
                 
as_acs$female <- c(as_acs$B01001_026E)

# Rename race columns

race_acs$white <- c(race_acs$B03002_003E)
race_acs$black <- c(race_acs$B03002_004E)
race_acs$native <- c(race_acs$B03002_005E)
race_acs$asian <- c(race_acs$B03002_006E)
race_acs$hawpi <- c(race_acs$B03002_007E)
race_acs$other <- c(race_acs$B03002_008E)
race_acs$mixed <- c(race_acs$B03002_009E+ 
                      race_acs$B03002_010E + 
                      race_acs$B03002_011E)
race_acs$latinx <-c(race_acs$B03002_012E)

# Delineate categories for household income

inc_acs$hhi1 <- c(inc_acs$B19001_002E + 
                    inc_acs$B19001_003E + 
                    inc_acs$B19001_004E + 
                    inc_acs$B19001_005E)

inc_acs$hhi2 <- c(inc_acs$B19001_006E + 
                    inc_acs$B19001_007E + 
                    inc_acs$B19001_008E + 
                    inc_acs$B19001_009E + 
                    inc_acs$B19001_010E)

inc_acs$hhi3 <- c(inc_acs$B19001_011E +
                    inc_acs$B19001_012E)
inc_acs$hhi4 <- c(inc_acs$B19001_013E)

inc_acs$hhi5 <- c(inc_acs$B19001_014E + 
                    inc_acs$B19001_015E)

inc_acs$highinc <- c(inc_acs$B19001_016E + inc_acs$B19001_017E)


# Delineate categories for employment status
# emp1 : civilian labor employed | emp0: civilian labor unemployed

 emp_acs$emp0 <- emp_acs$B23025_007E
 emp_acs$emp1 <- (emp_acs$B23025_002E)

# Delineate categories for nativity/foreign born status
# for0: native born | for1: foreign born

 nat_acs$for0 <- c(nat_acs$B05012_002E)
 nat_acs$for1 <- c(nat_acs$B05012_003E)

# Delineate categories for educational attainment
# et1: no highschool diploma | et2: highschool diploma, equivalent, or some college  | et3: associates or bachelor's |et4: graduate or professional school

 edu_acs$et1 <- c(edu_acs$B15003_002E +
                    edu_acs$B15003_003E +
                    edu_acs$B15003_004E +
                    edu_acs$B15003_005E +
                    edu_acs$B15003_006E +
                    edu_acs$B15003_007E +
                    edu_acs$B15003_008E +
                    edu_acs$B15003_009E +
                    edu_acs$B15003_010E +
                    edu_acs$B15003_011E +
                    edu_acs$B15003_012E +
                    edu_acs$B15003_013E +
                    edu_acs$B15003_014E +
                    edu_acs$B15003_015E +
                    edu_acs$B15003_016E)

 edu_acs$et2 <- c(edu_acs$B15003_017E +
                    edu_acs$B15003_018E +
                    edu_acs$B15003_019E +
                    edu_acs$B15003_020E)

 edu_acs$et3 <- c(edu_acs$B15003_021E +
                    edu_acs$B15003_022E)

 edu_acs$et4 <- c(edu_acs$B15003_023E +
                    edu_acs$B15003_024E +
                    edu_acs$B15003_025E)
 

# Delineate categories for language spoken at home
 
lang_acs$eng <- lang_acs$B06007_002E
lang_acs$noneng <- c(lang_acs$B06007_003E+lang_acs$B06007_006E)

lang_acs$lang4 <- c(lang_acs$B06007_004E + 
                  lang_acs$B06007_007E)

lang_acs$lang5 <- c(lang_acs$B06007_005E + 
                  lang_acs$B06007_008E)

# Delineate categories for school enrollment status
# se1: highschool or under | se2: undergraduate or graduate or professional school | se3: not enrolled in school

enr_acs$se1 <- c(enr_acs$B14001_003E +
                    enr_acs$B14001_004E +
                    enr_acs$B14001_005E +
                    enr_acs$B14001_006E +
                    enr_acs$B14001_006E)

enr_acs$se2 <- c(enr_acs$B14001_008E + enr_acs$B14001_009E)

enr_acs$se3 <- c(enr_acs$B14001_010E)

# Make new columns for Poverty Status Categories
pov_acs$povtotal <- c(pov_acs$B17001_002E)
```

```{r filter-acs}

# Filter ACS data for columns of interest and aggregate into one table 

as_tab <- as_acs %>% 
  dplyr::select(GEOID,child, teen, yad, mad, sen, male, female)

hhi_tab <- inc_acs %>%
  dplyr::select(GEOID, hhi1, hhi2, hhi3, hhi4, hhi5, highinc)

emp_tab <- emp_acs %>% 
  dplyr::select(GEOID, emp0, emp1)

nat_tab <- nat_acs %>% 
  dplyr::select(GEOID, for0, for1)

edu_tab <- edu_acs %>% 
  dplyr::select(GEOID, et1, et2, et3, et4)

race_tab <- race_acs %>% 
  dplyr::select(GEOID, white, black, native, asian, hawpi, mixed, latinx)

m_inc_tab <- m_inc_acs %>%
  dplyr::select(GEOID, B19013_001E)

lang_tab <-lang_acs %>%
  dplyr::select(GEOID, eng, noneng)

enr_tab <- enr_acs %>%
  dplyr::select(GEOID, se1, se2, se3)

pov_tab <- pov_acs %>% 
  dplyr::select(GEOID, povtotal)

# Join the ACS data to the table with Census Tract data

acs_table <- cook_tracts_tbl %>% inner_join(as_tab, by="GEOID")%>%
                                 inner_join(race_tab, by="GEOID") %>%
                                 inner_join(emp_tab, by="GEOID") %>% 
                                 inner_join(nat_tab, by="GEOID")%>% 
                                 inner_join(edu_tab, by="GEOID")%>%
                                 inner_join(lang_tab,by="GEOID")%>%
                                 inner_join(pov_tab, by="GEOID")%>%
                                 inner_join(hhi_tab, by= "GEOID")%>%

  mutate(tract=substr(GEOID, 1, 11)) %>%  arrange(tract)


```

## Calculating and applying the weighting factor 

I created a weighting factor that was the proportion of the census tract population in the individual block. This proportion was representative of the population contribution of an individual block towards the total population of the census tract that it belongs to. The proportion weight was then applied to the social demographic variables at the tract level so the result would be a weighted count by its population contribution.  

```{r weights}
# Calculate a  weighting factor that is the proportion of the census tract population in a every individual census block.This proportion is representative of the population contribution of an individual block towards the total population of the census tract that it belongs to.

weights_chi <- cook_blocks_tbl %>% 
  mutate(tract=substr(GEOID, 1, 11)) %>% 
  arrange(tract) %>% 
  merge(cook_tracts_tbl, by.x="tract", by.y="GEOID", all.x=T) %>% 
  mutate(block=substr(GEOID, 1, 16)) %>% 
  mutate(pop_wt=block_pop/tract_pop, hu_wt=block_hu/tract_hu)

```

```{r weights-mutate}
# Apply the proportional weight to the social demographic variables 

acs_table_wt <- weights_chi %>% merge(acs_table, by.x="tract", by.y="GEOID", all.x=T) %>% mutate(latinx_app=pop_wt*latinx)%>%
mutate(for_app=pop_wt*for1)%>%
mutate(bach_app=pop_wt*et3)%>%
mutate(unemp_app=pop_wt*emp0)%>%
mutate(black_app=pop_wt*black)%>%
mutate(white_app=pop_wt*white)%>%
mutate(lang_app=pop_wt*noneng)%>%
mutate(asian_app=pop_wt*asian)%>% 
mutate(povtot_app=pop_wt*povtotal)%>%
mutate(child_app=pop_wt*child)%>%
mutate(yad_app=pop_wt*yad)%>%
mutate(mad_app=pop_wt*mad)%>%
mutate(sen_app=pop_wt*sen)%>%
mutate(man_app=pop_wt*male)%>%
mutate(fem_app= pop_wt*female)%>% 
mutate(hinc_app=pop_wt*highinc)

```

Apportioning the social demographic data to the LSAs consisted of generating centroids from the blocks and doing a centroid assignment to the LSAs. Sociodemographic data was aggregated by the name of the library service area and summed. Apportioning the data in this way allowed me to profile the sociodemographic characteristics and be confident in the quality of the data outputs. Apportioning the data in this way maintained an acceptable degree of data precision and accuracy. From this step I could normalize the data by the population in the LSA and further aggregate by whether a library provided a service or not.  

```{r pop-weight-agg}

# Generate centroids for the blocks
centroids <- st_centroid(chi_blocks_shp)

# Join library names to centroids
vor_blocks <- st_join(chi_vor, centroids, join= st_intersects, left=TRUE)

# Join weights table to library service data
lib_service <- acs_table_wt %>% 
  merge(vor_blocks, by.x="GEOID", by.y="GEOID.y", all.x=T)

#Aggregate variable apportionments

agg_latinx <- aggregate(latinx_app ~ NAME, data = lib_service, sum)
agg_unemp <- aggregate(unemp_app ~ NAME, data= lib_service, sum)
agg_college <- aggregate(bach_app ~ NAME, data= lib_service, sum)
agg_foreign <- aggregate(for_app ~ NAME, data=lib_service, sum)
agg_white<- aggregate(white_app ~ NAME, data=lib_service, sum)
agg_black<-aggregate(black_app ~ NAME, data=lib_service, sum)
agg_asian<-aggregate(asian_app ~ NAME, data=lib_service, sum)
agg_pov <- aggregate(povtot_app ~ NAME, data=lib_service, sum)
agg_child <- aggregate(child_app ~ NAME, data=lib_service, sum)
agg_yad <- aggregate(yad_app ~ NAME, data=lib_service, sum)
agg_mad <- aggregate(mad_app ~ NAME, data=lib_service, sum)
agg_sen <- aggregate(sen_app ~ NAME, data=lib_service, sum)
agg_man <- aggregate(man_app ~ NAME, data=lib_service, sum)
agg_fem <- aggregate(fem_app ~ NAME, data= lib_service, sum)
agg_noneng <- aggregate(lang_app ~ NAME, data= lib_service, sum)
agg_pop <- aggregate(block_pop ~ NAME, data= lib_service, sum)
agg_hinc <- aggregate(hinc_app ~ NAME, data=lib_service,sum)

#join back to catchment layer
catchment <- chi_vor %>% merge(agg_latinx, by="NAME")%>% 
  merge(agg_unemp, by="NAME") %>% 
  merge(agg_college, by="NAME")%>% 
  merge(agg_foreign, by="NAME")%>% 
  merge(agg_white, by="NAME")%>%
  merge(agg_noneng, by= "NAME")%>%
  merge(agg_pop, by= "NAME")%>%
  merge(agg_black, by='NAME')%>%
  merge(agg_asian, by='NAME')%>% 
  merge(agg_pov, by='NAME')%>% 
  merge(agg_man, by= 'NAME')%>% 
  merge(agg_fem, by= 'NAME')%>% 
  merge(agg_child, by= 'NAME')%>% 
  merge(agg_yad, by= 'NAME')%>% 
  merge(agg_mad, by= 'NAME')%>% 
  merge(agg_sen, by= 'NAME')%>% 
  merge(agg_hinc, by='NAME')

```

```{r normalize}

catchment.norm <-catchment %>% 

mutate(black_norm=black_app/block_pop, white_norm=white_app/block_pop, bach_norm=bach_app/block_pop, asian_norm=asian_app/block_pop, latinx_norm=latinx_app/block_pop, unemp_norm=unemp_app/block_pop, for_norm=for_app/block_pop, lang_norm=lang_app/block_pop, pov_norm=povtot_app/block_pop, child_norm=child_app/block_pop, yad_norm=yad_app/block_pop, mad_norm=mad_app/block_pop, sen_norm=sen_app/block_pop, man_norm=man_app/block_pop, fem_norm=fem_app/block_pop, hinc_norm=hinc_app/block_pop)

```

### Joining website data to thiessen polygons

```{r web_vor_shp}

web_vor <- left_join(chi_vor, web, by="NAME")%>%
  st_set_crs(st_crs("+proj=utm +zone=16 +datum=WGS84"))

# make tibble 

web.new <- web_vor %>%
  mutate(HHELP=factor(HHELP, levels=c(0,1), labels=c( "No", "Yes"))) %>%
  mutate(CHBOOK=factor(CHBOOK, levels=c(0,1), labels=c( "No", "Yes"))) %>%
  mutate(UMEDIA=factor(UMEDIA, levels=c(0,1), labels=c( "No", "Yes"))) %>%
  mutate(MHSS=factor(MHSS, levels=c(0,1), labels=c( "No", "Yes"))) %>%
  mutate(CITCORNER=factor(CITCORNER, levels=c(0,1), labels=c( "No", "Yes")))%>%
  mutate(HSPOT=factor(HSPOT, levels=c(0,1), labels=c( "No", "Yes")))%>%
  mutate(CYBNAV=factor(CYBNAV, levels=c(0,1), labels=c( "No", "Yes")))%>%
  mutate(NE_MATER=factor(NE_MATER, levels=c(0,1), labels=c( "No", "Yes")))%>%
  mutate(IP_HHELP=factor(IP_HHELP, levels=c(0,1), labels=c( "No", "Yes")))%>%
  mutate(STROOMS=factor(STROOMS, levels=c(0,1), labels=c( "No", "Yes")))%>%
  mutate(COMP=factor(COMP, levels=c(0,1), labels=c( "No", "Yes")))%>% 
  st_drop_geometry()
             
```

```{r join-pred-out-vars}

# Join tables with predictor and outcome variables together for the statistical analysis

final_tbl <- full_join(catchment.norm, web.new, by="NAME")%>%
  drop_na(CHBOOK)%>%
  st_set_crs(st_crs("+proj=utm +zone=16 +datum=WGS84"))

```

# Results

```{r linear-regression}

reg.umedia <- glm(UMEDIA ~ block_pop + child_norm + sen_app + fem_app + black_norm + asian_norm + latinx_norm + unemp_norm + pov_norm + hinc_norm + for_norm + bach_norm, data = final_tbl, family = "binomial")

exp(coef(reg.umedia))

summary(reg.umedia)

reg.hspot <- glm(HSPOT ~ block_pop + child_norm + sen_app + fem_app + black_norm + asian_norm + latinx_norm + unemp_norm + pov_norm + hinc_norm + for_norm + bach_norm, data = final_tbl, family = "binomial")

exp(coef(reg.hspot))

summary(reg.hspot)

reg.chbook <- glm(CHBOOK ~ block_pop + child_norm + sen_app + fem_app + black_norm + asian_norm + latinx_norm + unemp_norm + pov_norm + hinc_norm + for_norm + bach_norm, data = final_tbl, family = "binomial")
exp(coef(reg.chbook))

summary(reg.chbook)

reg.mhss <- glm(MHSS ~ block_pop + child_norm + sen_app + fem_app + black_norm + asian_norm + latinx_norm + unemp_norm + pov_norm + hinc_norm + for_norm + bach_norm, data = final_tbl, family = "binomial")

exp(coef(reg.mhss))

summary(reg.mhss)

reg.citcor <- glm(CITCORNER ~ block_pop + child_norm + sen_app + fem_app + black_norm + asian_norm + latinx_norm + unemp_norm + pov_norm + hinc_norm + for_norm + bach_norm, data = final_tbl, family = "binomial")

exp(coef(reg.citcor))

summary(reg.citcor)

reg.cybnav <- glm(CYBNAV ~ block_pop + child_norm + sen_app + fem_app + black_norm + asian_norm + latinx_norm + unemp_norm + pov_norm + hinc_norm + for_norm + bach_norm, data = final_tbl, family = "binomial")

exp(coef(reg.cybnav))

summary(reg.cybnav)

```

##MAPS!

```{r map-catchment}
tmap_style("white")
tm_predictor <-tmap_mode("plot")

tm_shape(catchment.norm) +
  tm_polygons(col="hinc_norm", style="pretty",palette = brewer.pal(n = 5, name = "Oranges"), title="% High Income", lwd= NA, border.col="lightgrey") +
  tm_layout(legend.width=3, legend.text.size = .6, legend.title.size = .8, asp=0.8)+ 
  tm_shape(catchment) + 
  tm_borders("white", lwd = .5)+ 
  tm_shape(chi)+ 
  tm_borders("darkgrey", lwd=.5)

tm_predictor



```

```{r map-outcome}
tm_outcome2 <- tmap_mode("plot")
tm_shape(final_tbl) +
  tm_polygons(col="vist_norm", palette = brewer.pal(n = 5, name = "Greens"), style="jenks", title="VIST per capita", lwd= NA, border.col="lightgrey") +
  tm_layout(legend.width=3, legend.text.size = .6, legend.title.size = .8, asp=0.8)+ 
  tm_shape(catchment) + 
  tm_borders("white", lwd = .5)+ 
  tm_shape(chi)+ 
  tm_borders("darkgrey", lwd=.5)

tm_outcome2
```

```{r race-map}

acs_data <- st_join(chi_tracts_shp, catchment.norm)


race_pop <- mutate(acs_data, majRace = case_when(
  white_norm > 0.55 ~ 'White',
  black_norm > 0.55 ~ 'Black',
  asian_norm > 0.55 ~ 'Asian',
  latinx_norm > 0.55 ~ 'Latino',
  TRUE ~ 'No Majority'
))

tmap_style("white")
tm_racemaj <-tmap_mode("plot")

tm_racemaj<- tm_shape(race_pop) +
  tm_polygons(col="majRace", title="Racial Majority by Tract", lwd= NA, border.col="lightgrey") +
  tm_layout(legend.width=3, legend.text.size = .6, legend.title.size = .8, asp=0.8)+ 
  tm_shape(chi)+ 
  tm_borders("darkgrey", lwd=.5)

tm_racemaj

```
```{r outliers}
web %>% identify_outliers(VIST)%>%
  print(width=Inf)

no_outliers_vist <- web %>% filter(web$VIST < 116554)
no_outliers_circ <- web %>% filter(web$CIRC < 142413)
no_outliers_comp <- web %>% filter(web$COMPSES < 23702)

boxplot(no_outliers_vist$VIST)
boxplot(no_outliers_circ$CIRC)
boxplot(no_outliers_comp$COMPSES)
```

```{r mapping-web}

tm_outcome <-tmap_mode("plot")
tm_shape(final_tbl) +
  tm_polygons("CITCORNER",palette = c("No" = "#44a5c2", "Yes" = "#ffae49"), title="Citizenship Corner", lwd= NA, border.col="lightgrey") +
  tm_layout(legend.width=3, legend.text.size = 1.5, legend.title.size = 2, asp=0.8) + 
  tm_shape(catchment) + 
  tm_borders("white", lwd = .5)+ 
  tm_shape(chi)+ 
  tm_borders("darkgrey", lwd=.5)

tm_outcome

tm_outcome2 <- tmap_mode("plot")
tm_shape(final_tbl) +
  tm_polygons(col="COMPSES", palette = brewer.pal(n = 5, name = "Greens"), style="jenks", title="Computer Sessions", lwd= NA, border.col="lightgrey") +
  tm_layout(legend.width=3, legend.text.size = .6, legend.title.size = .8, asp=0.8)+ 
  tm_shape(catchment) + 
  tm_borders("white", lwd = .5)+ 
  tm_shape(chi)+ 
  tm_borders("darkgrey", lwd=.5)

tm_outcome2
```

```{r filter-bars}

hspot_summary <- final_tbl %>% 
  group_by(HSPOT)%>% 
  summarize(
    total_pop=sum(block_pop),
    total_child=sum(child_app)/total_pop,
    total_sen=sum(sen_app)/total_pop, 
    total_fem=sum(fem_app)/total_pop,
    total_black=sum(black_app)/total_pop,
    total_latinx=sum(latinx_app)/total_pop,
    total_asian=sum(asian_app)/total_pop,
    total_unemp=sum(unemp_app)/total_pop,
    total_pov=sum(povtot_app)/total_pop,
    total_hinc=sum(hinc_app)/total_pop,
    total_for=sum(for_app)/total_pop,
    total_bach=sum(bach_app)/total_pop)


chbook_summary <- final_tbl %>% 
  group_by(CHBOOK)%>% 
  summarize(
    total_pop=sum(block_pop),
    total_child=sum(child_app)/total_pop,
    total_sen=sum(sen_app)/total_pop, 
    total_fem=sum(fem_app)/total_pop,
    total_black=sum(black_app)/total_pop,
    total_latinx=sum(latinx_app)/total_pop,
    total_asian=sum(asian_app)/total_pop,
    total_unemp=sum(unemp_app)/total_pop,
    total_pov=sum(povtot_app)/total_pop,
    total_hinc=sum(hinc_app)/total_pop,
    total_for=sum(for_app)/total_pop,
    total_bach=sum(bach_app)/total_pop)

umedia_summary<- final_tbl %>% 
  group_by(UMEDIA)%>% 
  summarize(
    total_pop=sum(block_pop),
    total_child=sum(child_app)/total_pop,
    total_sen=sum(sen_app)/total_pop, 
    total_fem=sum(fem_app)/total_pop,
    total_black=sum(black_app)/total_pop,
    total_latinx=sum(latinx_app)/total_pop,
    total_asian=sum(asian_app)/total_pop,
    total_unemp=sum(unemp_app)/total_pop,
    total_pov=sum(povtot_app)/total_pop,
    total_hinc=sum(hinc_app)/total_pop,
    total_for=sum(for_app)/total_pop,
    total_bach=sum(bach_app)/total_pop)

mhss_summary<- final_tbl %>% 
  group_by(MHSS)%>% 
  summarize(
    total_pop=sum(block_pop),
    total_child=sum(child_app)/total_pop,
    total_sen=sum(sen_app)/total_pop, 
    total_fem=sum(fem_app)/total_pop,
    total_black=sum(black_app)/total_pop,
    total_latinx=sum(latinx_app)/total_pop,
    total_asian=sum(asian_app)/total_pop,
    total_unemp=sum(unemp_app)/total_pop,
    total_pov=sum(povtot_app)/total_pop,
    total_hinc=sum(hinc_app)/total_pop,
    total_for=sum(for_app)/total_pop,
    total_bach=sum(bach_app)/total_pop)

citcorner_summary <- final_tbl %>% 
  group_by(CITCORNER)%>% 
  summarize(
    total_pop=sum(block_pop),
    total_child=sum(child_app)/total_pop,
    total_sen=sum(sen_app)/total_pop, 
    total_fem=sum(fem_app)/total_pop,
    total_black=sum(black_app)/total_pop,
    total_latinx=sum(latinx_app)/total_pop,
    total_asian=sum(asian_app)/total_pop,
    total_unemp=sum(unemp_app)/total_pop,
    total_pov=sum(povtot_app)/total_pop,
    total_hinc=sum(hinc_app)/total_pop,
    total_for=sum(for_app)/total_pop,
    total_bach=sum(bach_app)/total_pop)

```


``` {r rename}
colnames(web) <- c('NAME','Circulation','Visitation', 'Hotspot Lending', 'Chromebook Lending', 'Homework Help','InPerson Homework Help', 'OL_HHELP', 'WL_HHELP', 'Citizenship Corner', 'CyberNavigators', 'OL_CYBNAV', 'WL_CYBNAV', 'Study Rooms', 'N_STROOMS','Meeting Room', 'YouMedia', 'NonEnglish Materials', 'LANG1', 'LANG2', 'LANG3', 'Computers', 'Computer Sessions', 'Mental Health Services')
```

```{r stacked-bar}
 # web%>%
 #   select(NAME, NE_MATER,IP_HHELP, CYBNAV, CITCORNER, MHSS, HSPOT, CHBOOK, UMEDIA, MTROOMS, STROOMS)%>%
 #   pivot_longer(!NAME, names_to="service", values_to="provides")%>%
 #   mutate(provides=factor(provides, levels=c("0","1"), labels=c("No","Yes")))%>%
 #   ggplot(aes(y=service, fill=provides))+
 #   geom_bar(stat="count")

web %>% 
  select(NAME, `NonEnglish Materials`, `InPerson Homework Help`, CyberNavigators, `Citizenship Corner`, `Mental Health Services`, `Hotspot Lending`, `Chromebook Lending`, YouMedia, `Meeting Room`, `Study Rooms`)%>%
  pivot_longer(!Name, names_to="service", values_to="provides")%>%
  mutate(provides=factor(provides, levels=c("0","1"), labels=c("No","Yes")))%>%
  ggplot(aes(y=service, fill=provides))+
  geom_bar(stat="count")+ 
  scale_fill_manual(values = c("No" = "#44a5c2", "Yes" = "#ffae49")) +
  labs(x= "Count", y = "Service", fill = "Provides") +
  theme_light()


```

```{r desc_stats_pred}
# foreign born 

hist(catchment$for_app, breaks=50)

median(catchment$for_app) 
sd(catchment$for_app)
min(catchment$for_app)
max(catchment$for_app)

# unemployed

hist(catchment$unemp_app, breaks=50)
mean(catchment$unemp_app)
median(catchment$unemp_app)
sd(catchment$unemp_app)
min(catchment$unemp_app)
max(catchment$unemp_app)

# latinx

hist(catchment$latinx_app, breaks=50)
median(catchment$latinx_app)
mean(catchment$latinx_app)
sd(catchment$latinx_app)
min(catchment$latinx_app)
max(catchment$latinx_app)

# has a college degree
hist(catchment$bach_app, breaks=50)
median(catchment$bach_app)
mean(catchment$bach_app)
sd(catchment$bach_app)
min(catchment$bach_app) 
max(catchment$bach_app)

# female 
# 
# hist(catchment$fem_app, breaks=50)
# median(catchment$fem_app)
# mean(catchment$fem_app)
# sd(catchment$fem_app)
# min(catchment$fem_app)
# max(catchment$fem_app)

# language spoken at home is a language other than english 
hist(catchment$lang_app, breaks=50)
median(catchment$lang_app)
mean(catchment$lang_app)
min(catchment$lang_app)
max(catchment$lang_app)

# population 

hist(catchment$block_pop, breaks=50)
median(catchment$block_pop)
mean(catchment$block_pop)
sd(catchment$block_pop)
min(catchment$block_pop)
max(catchment$block_pop)

# poverty status 

hist(catchment$povtot_app, breaks=50)
median(catchment$povtot_app)
mean(catchment$povtot_app)
sd(catchment$povtot_app)
min(catchment$povtot_app)
max(catchment$povtot_app)


```


```{r scatter-test}

ggplot(web, aes(x = VIST, y = CIRC)) +
  geom_point(size = 2) +
  geom_text(aes(label = NAME), vjust = -1, size= 2)
```



```{r traditiona-lgm}
# trad

reg.circ <- lm(CIRC ~ black_norm + asian_norm + for_norm + unemp_norm + latinx_norm + bach_norm + pov_norm , data = join_web)


summary(reg.circ)

reg.vist <- lm(VIST ~ black_norm + asian_norm + for_norm + unemp_norm + latinx_norm + bach_norm + pov_norm , data = join_web)


summary(reg.vist)

reg.compses <- lm(COMPSES ~ black_norm + asian_norm + for_norm + unemp_norm + latinx_norm + bach_norm + pov_norm , data = join_web)


summary(reg.compses)

```

```{r block-tract-figure}
tract <- chi_tracts_shp %>%
  dplyr::filter(GEOID == '17031290900')


blocks <- left_join(cook_blocks_shp, cook_blocks_tbl)%>%
   st_intersection(tract)%>% 
   st_collection_extract("POLYGON")%>%
   select(GEOID, block_pop, geometry)

no_pop <- blocks %>% 
  dplyr::filter(block_pop == 0)


```

```{r map-blocks}

block_figure <- tmap_mode("plot")
tm_shape(blocks) +
  tm_polygons(col="block_pop", palette = brewer.pal(n = 5, name = "YlOrRd"), style="jenks", title="Population in Block", lwd= NA, border.col="white", labels = c("1 to 16", "16 to 43", "43 to 78", "78 to 114", "114 to 168")) +
  tm_layout(legend.width=3, legend.text.size = .6, legend.title.size = .8, asp=0.8)+
  tm_shape(no_pop)+ 
  tm_polygons(col ="lightgrey", lwd=NA, border.col="white")+ 
  tm_shape(tract) + 
  tm_borders("black", lwd = 1)+ 
  tm_add_legend(type = c("fill"), 
                labels = 'No Population', 
                col= "lightgrey", border.col = "white", lwd=NA)

block_figure
```

# Discussion

Under construction. 

# Integrity Statement

The authors of this preregistration state that they completed this preregistration to the best of their knowledge and that no other preregistration exists pertaining to the same hypotheses and research.

This report is based upon the template for Reproducible and Replicable Research in Human-Environment and Geographical Sciences, DOI:[10.17605/OSF.IO/W29MQ](https://doi.org/10.17605/OSF.IO/W29MQ)

# References
Flitter, H., Weckenbrock, P., & Weibel, R. (n.d.). Thiessen Polygon. Retrieved December 16, 2023, from http://www.gitta.info/Accessibilit/en/html/UncProxAnaly_learningObject4.html
